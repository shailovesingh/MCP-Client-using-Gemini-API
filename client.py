import os
import asyncio
import sys
import json

from typing import Optional
from contextlib import AsyncExitStack  # For Managing multiple async tasks
from mcp import ClientSession, StdioServerParameters # MCP session management
from mcp.client.stdio import stdio_client #MCP client for standard I/O communication

# Import Google's Gen Ai SDK
from google import genai
from google.genai import types
from google.genai.types import Tool, FunctionDeclaration
from google.genai.types import GenerateContentConfig

from dotenv import load_dotenv
load_dotenv()

class MCPClient:
    def __init__(self):
        """Initialize the MCP client and configure the Gemini API."""
        self.session: Optional[ClientSession] = None ## MCP session for communication
        self.exit_stack = AsyncExitStack()  # Manages async resource cleanup

        # Retrieve the Gemini API key from environment variables
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found. Please add it to your .env file.")
        

        # COnfigure the Gemini Ai client
        self.genai_client = genai.client(api_key = gemini_api_key)

    async def connect_to_server(self, server_script_path: str):
        """Connect to the MCP server and list available tools."""

        # Determine whether the server script is written in Pythom or Javasvript
        # This allows us to ececute the correct command to start the MCP server
        command = "python" if server_script_path.endswith('.py') else "node" 

        # Define the parameters for connecting to the MCP server
        server_params = StdioServerParameters(command=command, args=[server_script_path])

        # Establish communication with the MCP server using standard input/output (stdio)
        stidio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))

        # Extract the read/write streams from the transport object
        self.stdio, self.write = stidio_transport

        # Initialize the MCP client session, which allows interaction with the server
        self.sessio = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))

        # Send an initialization request to the MCP server
        await self.session.initialize()

        # Request the list of available tools from the MCP server
        response = await self.session.list_tools()
        tools = response.tools # Extract the tool list from the response

        # PRint a message showing the names of the tools available on the server

        print("\nConnected to server with tools:", [tool.name for tool in tools])

        # Convert MCO tools to Gemini format
        self.function_declarations = convert_mcp_tools_to_gemini(tools)

    
    async def process_query(self, query: str) -> str:
        """
        Process a user query using the Geminin API and execute tool calls if needed.

        Args:
            query (str): The user's input query.

        Returns:
            str: The response generated by the Gemini model.
        """

        # Format user input as a structured Content object for Gemini
        user_prompt_content = types.Content(
            role = "user" # Indicates that this is a user message
            parts = [types.Part.from_text(text=query)] # Convert the text query into a gemini-compatible format
        )

        # Send user input to Gemini AI and include available tools for function calling

        response = self.genai_client.models.generate_content(
            model = 'gemini-2.0-flash-001'  # Specifies which Gemini model to use
            contents = [user_prompt_content], # Send user input to Gemini
            config = types.GenerateContentConfig(
                tools = self.function_declartions,  # Pass the list of available MCP tools for Gemini to use

            ),
        )
    
        # Initialize variables to store final response text and assistant messages
        final_text = [] # Stores the final formatted response
        assistant_message_content = [] # Stores assistant response

        # Process the respinse received from Gemini
        for candidate in response.candidates:
            if candidate.content.parts: # Ensure response has content
                for part in candidate.content.parts:
                    if isinstance(part, types.part): # Check if part is a valid Gemini response unit
                        if part.function_call: # If Gemini suggests a function call, process it

                            # Extract function call details
                            function_call_part = part # Store the function call response
                            tool_name = function_call_part.function_call.name # Name of the MCP tool Gemini wants to call

                            tool_args = function_call_part.functiom_call.args # Arguments required for the tool execution

                            # Print debug info: Which tool is being called and with what arguments
                            print(f"\n[Gemini requested tool call: {tool_name} with args {tool_args}]")

                            
                            try:
                                result = await self.session.call_tool(tool_name, tool_args) ## Call MCP tool with arguments

                                function_response = {"result": result.content} # 
            

